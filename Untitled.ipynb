{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamed0yaser/python/blob/main/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "W0iEBSDTjt83"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries"
      ],
      "metadata": {
        "id": "Cm02Cse8jv8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load your dataset."
      ],
      "metadata": {
        "id": "_nWOH4--kk77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a Pandas DataFrame\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Split the dataset into features and labels\n",
        "features = df[['Temperature', 'Humidity', 'Light', 'Rain', 'SoilMoisture']]\n",
        "labels = df['Label']\n"
      ],
      "metadata": {
        "id": "f2mmbfpAkgN3"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMcCJbUEmVg-",
        "outputId": "3a279099-3f46-4131-893f-d514cfb666a1"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize the features.\n",
        ":"
      ],
      "metadata": {
        "id": "bzqBmEwak3PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features to the range [0, 1]\n",
        "features = (features - features.min()) / (features.max() - features.min())\n"
      ],
      "metadata": {
        "id": "jTbDP1Zxk7Z-"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle the dataset.\n"
      ],
      "metadata": {
        "id": "eoDrjEW5lId_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the dataset to prevent overfitting\n",
        "df = pd.DataFrame(features)\n",
        "\n",
        "# Shuffle the DataFrame\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(df)\n",
        "\n",
        "# Shuffle the dataset to prevent overfitting\n",
        "dl = pd.DataFrame(labels)\n",
        "\n",
        "# Shuffle the DataFrame\n",
        "dl = dl.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(dl)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSMBRZxilLk1",
        "outputId": "e6bdad92-d5a2-4db7-e7aa-cf865290894d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Temperature  Humidity  Light     Rain  SoilMoisture\n",
            "0           0.2645  0.881220    1.0  0.36175      0.356089\n",
            "1           0.5380  0.641160    0.0  0.22175      0.505126\n",
            "2           0.5125  0.597149    0.5  0.09525      0.053263\n",
            "3           0.7190  0.170293    0.0  0.12850      0.312078\n",
            "4           0.5475  0.564891    1.0  0.06000      0.746937\n",
            "...            ...       ...    ...      ...           ...\n",
            "19495       0.5255  0.097524    0.5  0.09650      0.330583\n",
            "19496       0.6525  0.911478    1.0  0.45675      0.215554\n",
            "19497       0.6780  0.467117    0.5  0.21575      0.404851\n",
            "19498       0.3875  0.731933    0.5  0.16200      0.770693\n",
            "19499       0.8945  0.208552    0.0  0.14575      0.489872\n",
            "\n",
            "[19500 rows x 5 columns]\n",
            "           Label\n",
            "0      Raspberry\n",
            "1          Peach\n",
            "2         Pepper\n",
            "3           Corn\n",
            "4          Peach\n",
            "...          ...\n",
            "19495      Apple\n",
            "19496    Soybean\n",
            "19497     Potato\n",
            "19498      Peach\n",
            "19499     Cherry\n",
            "\n",
            "[19500 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into training and testing sets.\n",
        "Split the dataset into 80% training and 20% testing sets"
      ],
      "metadata": {
        "id": "WIq_cDhdlPUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2)"
      ],
      "metadata": {
        "id": "7s68uCUzlawA"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the CNN model."
      ],
      "metadata": {
        "id": "UqqZVQESlfg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    # A 2D convolutional layer with 32 filters of size 3x3\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    # A max pooling layer with pool size 2x2\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    # Another convolutional layer with 64 filters of size 3x3\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    # Another max pooling layer with pool size 2x2\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    # A flatten layer to convert the 2D feature maps to a 1D vector\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # A fully connected layer with 128 neurons\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    # A dropout layer to prevent overfitting\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # A fully connected layer with 1 neuron\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "SgccNJlZljH_"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model.\n"
      ],
      "metadata": {
        "id": "fLgNqpFUlpmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with the Adam optimizer and the categorical cross-entropy loss function\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "LrncxxWUlsl7"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model.\n"
      ],
      "metadata": {
        "id": "Y9XGcc8Clvkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_features, train_labels, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "zbiCFfSKlyLX",
        "outputId": "3c9978de-f1f5-4662-8a73-7bec85d1fd7a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-4407a6317dab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_9' (type Sequential).\n    \n    Input 0 of layer \"conv2d_14\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 5)\n    \n    Call arguments received by layer 'sequential_9' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 5), dtype=float64)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    }
  ]
}